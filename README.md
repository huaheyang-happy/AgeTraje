# 项目中文文档

## 1. 项目概述

`scglue` (Graph-Linked Unified Embedding) 是一个强大的深度学习框架，专注于单细胞多组学数据的整合与分析。在生物学研究中，单细胞技术能够从不同维度（如基因表达、染色质可及性、蛋白质丰度等）捕获细胞的异质性。然而，如何有效地整合这些异构数据，构建一个统一的、可解释的细胞状态表示，是当前生物信息学领域面临的关键挑战。

`scglue` 项目中的 `CGLUE-SOE-OT` 模型旨在解决这一挑战。它结合了多种先进的机器学习和统计学原理，包括：

*   **条件变分自编码器 (Conditional Variational Autoencoder, CVAE)**：用于学习数据的低维潜在表示。
*   **监督序数嵌入 (Supervised Ordinal Embedding, SOE)**：利用细胞类型或发育阶段等有序标签信息，在潜在空间中构建有意义的生物学梯度。
*   **最优传输 (Optimal Transport, OT)**：作为一种强大的数学工具，用于对齐不同模态的潜在分布，从而实现无缝的数据整合。

通过这些技术的结合，`CGLUE-SOE-OT` 模型能够：
1.  学习一个共享的、低维的潜在空间，有效整合来自不同单细胞模态的数据。
2.  在潜在空间中编码生物学上的有序关系（例如细胞分化轨迹、疾病进展阶段）。
3.  提供一个灵活且可解释的框架，用于理解复杂的细胞异质性和多组学相互作用。

## 2. 项目结构

`scglue` 项目的目录结构清晰，主要分为以下几个部分：

*   **`./` (根目录):** 包含项目级别的配置文件和核心模块的入口。
    *   `__init__.py`: 定义 `scglue` 包的顶层结构，导入核心模块。
    *   `data.py`, `genomics.py`, `graph.py`, `metrics.py`, `num.py`, `check.py`: 提供数据处理、基因组学操作、图论、性能评估、数值计算和数据校验等通用工具函数。
*   **`model/`:** 包含 `scglue` 框架中所有模型的定义和实现。
    *   `__init__.py`: 定义 `model` 子包的结构，导入具体的模型类。
    *   `base.py`: 定义模型和训练器的抽象基类。
    *   `cglue_soe_ot.py`: `CGLUE-SOE-OT` 模型的核心实现。
    *   `cglue_soe_components_ot.py`: `CGLUE-SOE-OT` 模型特有的组件，如条件编码器和损失函数。
    *   `glue.py`, `scglue.py`: 可能包含旧版或不同变体的 GLUE 模型实现。
    *   `data.py`, `dx.py`, `nn.py`, `plugins.py`, `prob.py`, `sc.py`: 模型相关的辅助模块，如数据加载器、诊断工具、神经网络层、训练插件、概率分布和单细胞特有功能。
*   **`examples/`:** 包含使用 `scglue` 模型的示例 Jupyter Notebooks。这些 Notebooks 展示了如何配置数据、训练模型、进行分析和可视化结果。

## 3. 核心模块详解

### 3.1 `model/base.py` - 模型和训练器的基石

`base.py` 文件定义了 `scglue` 框架中所有模型和训练器的抽象基类，为构建可扩展和模块化的深度学习模型提供了基础。

*   **`Trainer` 类:**
    *   **作用:** 这是一个抽象训练器类，负责管理神经网络 (`torch.nn.Module`) 的训练过程。它利用 `PyTorch-Ignite` 库来处理训练循环、事件（如 `EPOCH_STARTED`, `EPOCH_COMPLETED` 等）和指标计算。
    *   **核心功能:**
        *   要求子类实现 `train_step` 和 `val_step` 方法，分别定义单次训练和验证的逻辑。
        *   处理指标报告、异常处理（包括用户中断 `KeyboardInterrupt`）。
        *   支持集成 `TrainingPlugin` 以扩展训练功能。
        *   管理训练状态的保存和加载（具体实现由子类完成）。
    *   **原理:** 通过抽象化训练流程，`Trainer` 类使得不同的模型可以共享一套通用的训练基础设施，提高了代码的复用性和可维护性。

*   **`Model` 类:**
    *   **作用:** 这是一个抽象模型类，封装了一个神经网络 (`_net`) 及其对应的 `Trainer`。
    *   **核心功能:**
        *   `NET_TYPE` 和 `TRAINER_TYPE` 类属性允许子类指定具体的网络和训练器类型。
        *   `compile` 方法用于初始化模型的训练器，准备模型进行训练。
        *   提供 `fit` 和 `get_losses` 方法作为训练器对应方法的别名，简化用户接口。
        *   `save` 方法用于序列化模型（仅保存网络，不包括训练器状态），通常使用 `dill` 库。
    *   **原理:** `Model` 类提供了一个高层次的接口来管理神经网络的生命周期，从构建到训练再到保存和加载，使得用户可以更专注于模型的设计而非底层的训练细节。

*   **`TrainingPlugin` 类:**
    *   **作用:** 这是一个抽象插件类，用于通过自定义功能扩展训练过程。
    *   **核心功能:** 子类必须实现 `attach` 方法，以便在 `PyTorch-Ignite` 引擎上注册事件处理器，从而在训练的不同阶段执行自定义操作。
    *   **原理:** 插件机制增强了训练框架的灵活性，允许开发者在不修改核心训练逻辑的情况下添加新的功能，如学习率调度、日志记录、模型检查点等。

### 3.2 `model/cglue_soe_ot.py` - CGLUE-SOE-OT 模型的核心实现

`cglue_soe_ot.py` 文件是 `CGLUE-SOE-OT` 模型的核心，定义了其网络架构、训练逻辑和公共 API。

*   **`CGLUESOE_OT_Network` (神经网络结构):**
    *   **作用:** 定义了 `CGLUE-SOE-OT` 模型的神经网络架构，是一个 `torch.nn.Module`。
    *   **组件:**
        *   `x2u` (ConditionalDataEncoder): 一个 `ModuleDict`，将模态键（如 'rna', 'atac'）映射到 `ConditionalDataEncoder` 实例。这些编码器接收输入数据 (`x` 或 `xrep`) 和一个独热编码的标签 (`y_onehot`)，生成潜在表示 (`u`)。这是模型的“编码”部分。
        *   `u2x` (Decoders): 一个 `ModuleDict`，将模态键映射到各种数据解码器（如 `NormalDataDecoder`, `ZINBDataDecoder`）。这些解码器从潜在表示 (`u`) 和其他信息（如批次 `xbch` 或文库大小 `l_k`）重建原始数据 (`x`)。这是模型的“解码”部分。
        *   `prior`: 一个先验分布（通常是标准正态分布），用于潜在空间的正则化。
        *   `feature_embeddings`: 一个 `nn.Embedding` 层，学习每个特征（如基因、峰）在所有模态中的嵌入。这些嵌入 (`v_k`) 被解码器使用。
        *   `vertices`: 一个 `pd.Index`，包含模型中考虑的所有特征（基因/峰）的名称。
    *   **原理:** 这是一个变分自编码器 (VAE) 架构。`x2u` 作为编码器，将高维输入数据映射到低维潜在空间 (`u`)。`u2x` 作为解码器，从潜在空间重建输入。`prior` 对潜在空间进行正则化。`feature_embeddings` 允许跨模态共享特征表示。

*   **`CGLUESOE_OT_Trainer` (训练器):**
    *   **作用:** 继承自 `base.Trainer`，实现了 `CGLUESOE_OT_Network` 的具体训练和验证步骤。
    *   **损失函数:**
        *   **VAE 损失:**
            *   `x_nll` (Negative Log-Likelihood): 每种模态的重建损失，衡量解码器重建输入数据的效果。
            *   `x_kl` (Kullback-Leibler Divergence): 每种模态的正则化损失，确保潜在分布 `u` 接近先验分布。
            *   `x_elbo`: 证据下界 (Evidence Lower Bound)，即 `x_nll + lam_kl * x_kl`。
        *   **`triplet_loss` (三元组损失):** 通过 `calculate_triplet_loss` 计算。该损失鼓励具有相似标签（如细胞类型、发育阶段）的细胞在潜在空间中更接近，而不同标签的细胞则更远，同时尊重标签的序数关系。
        *   **`ot_loss` (最优传输损失):** 通过 `calculate_minibatch_uot_loss` 计算。该损失旨在对齐不同模态的潜在分布，通过最小化从一个分布转换到另一个分布的“成本”来实现整合。这是多组学整合的关键组成部分。
        *   `total_loss`: VAE ELBOs、三元组损失和最优传输损失的加权和。
    *   **训练过程:**
        *   `train_step`: 执行前向传播，计算所有损失，反向传播 `total_loss`，并使用优化器（如 Adam）更新网络参数。
        *   `val_step`: 在不计算梯度的情况下执行前向传播，评估验证集上的损失。
        *   `fit`: 使用 `ignite` 引擎协调训练循环，处理数据加载 (`AnnDatasetWithLabels`, `SCGLUEDataLoader`)、早停、学习率调度和检查点保存。它还跟踪并存储损失历史。
    *   **原理:** 训练器实现了多目标优化策略。它同时优化数据重建 (VAE)、潜在空间正则化 (KL)、标签感知嵌入 (三元组损失) 和跨模态整合 (最优传输)。

*   **`CGLUESOE_OT_Model` (模型接口):**
    *   **作用:** `CGLUE-SOE-OT` 模型的公共 API，继承自 `base.Model`。
    *   **初始化 (`__init__`):** 接收多个模态的 `AnnData` 对象和特征列表 (`vertices`)。根据模态配置动态创建 `x2u` 编码器和 `u2x` 解码器。初始化 `feature_embeddings` 和 `prior`。
    *   **`compile`:** 使用特定的超参数（如损失权重 `lam_data`, `lam_kl`, `lam_triplet`, `lam_ot`、三元组边距、OT 参数和学习率）配置 `CGLUESOE_OT_Trainer`。
    *   **`fit`:** 调用训练器的 `fit` 方法，处理 `max_epochs`, `patience` 和 `reduce_lr_patience` 的自动确定。存储 `loss_history`。
    *   **`plot_loss_curves`:** 绘制训练和验证损失曲线的实用函数。
    *   **`encode_data`:** 将新的 `AnnData` 对象编码到潜在空间。
    *   **`get_feature_embeddings`:** 获取学习到的特征嵌入。
    *   **`save` 和 `load`:** 用于序列化和反序列化模型状态（网络、训练器、损失历史、配置）。
    *   **原理:** 提供了一个高级的、用户友好的接口来构建、训练和使用 `CGLUE-SOE-OT` 模型，抽象了网络架构和训练循环的复杂性。

*   **`configure_dataset_cglue_soe` (数据集配置函数):**
    *   **作用:** 通过向 `adata.uns[config.ANNDATA_KEY]` 添加必要的配置，为 `AnnData` 对象准备 `CGLUE-SOE-OT` 模型的使用。
    *   **关键配置:**
        *   `prob_model`: 指定数据的概率模型（如 "Normal", "ZINB"）。
        *   `use_highly_variable`: 是否使用高变基因/特征。
        *   `use_layer`, `use_rep`: 指定 `adata` 中用作输入的层或表示。
        *   `use_batch`: 用于批次校正的批次信息。
        *   `use_label`: **至关重要，它指定了 `adata.obs` 中包含序数标签（如细胞类型、发育阶段）的列，用于三元组损失。** 它确保标签被视为有序分类数据。
        *   `features`, `rep_dim`, `batches`, `labels_ordered`, `label_dim`: 为模型配置存储的派生属性。
    *   **原理:** 此函数作为数据预处理和元数据标注步骤，确保 `AnnData` 对象包含所有必要信息，并以标准化格式供模型使用。`use_label` 参数对于模型的监督学习方面（序数嵌入）至关重要。

### 3.3 `model/cglue_soe_components_ot.py` - CGLUE-SOE-OT 模型组件

`cglue_soe_components_ot.py` 文件提供了 `CGLUE-SOE-OT` 模型中使用的关键组件的详细实现。

*   **`ConditionalDataEncoder` (条件数据编码器):**
    *   **作用:** 实现每个模态 `k` 的编码器 `q(u | x^(k), y^(k); phi^(k))`。它接收输入数据 `x` 和独热编码的标签 `y`（如细胞类型），并输出潜在空间 `u` 中高斯分布的参数（均值 `loc` 和标准差 `std`）。
    *   **架构:** 一个多层感知机 (MLP)。输入是原始/表示数据 `x` 和独热编码标签 `y` 的拼接。隐藏层包含线性变换、`LeakyReLU` 激活、`BatchNorm1d` 和 `Dropout`。输出层生成潜在高斯分布的均值和标准差。
    *   **原理:** 通过对编码器进行标签条件化，模型鼓励潜在空间以一种分离不同细胞类型或有标签组的方式进行结构化，使学习到的表示更具可解释性。

*   **`calculate_triplet_loss` (三元组损失计算):**
    *   **作用:** 实现三元组损失，这是模型“监督序数嵌入” (SOE) 方面的核心组成部分。它强制在不同标签组的潜在表示之间建立特定的排序或关系。
    *   **机制:**
        *   首先计算当前小批量中每个类别的质心（平均嵌入）。
        *   然后遍历特定的类别三元组 `(c, c+1, h)`，其中 `c` 是一个类别，`c+1` 是有序序列中的下一个类别，`h` 是序列中更远的类别 (`h >= c+2`)。
        *   对于每个三元组，计算 `c` 和 `c+1` 质心之间的平方欧氏距离 (`d(c, c+1)^2`)，以及 `c` 和 `h` 之间的平方欧氏距离 (`d(c, h)^2`)。
        *   每个三元组的损失项为 `max(0, d(c, c+1) + margin - d(c, h))^2`。这旨在使相邻类别之间的距离小于 `c` 与更远类别 `h` 之间的距离，至少相差一个 `margin`。
    *   **原理:** 该损失函数专为**序数关系**设计。例如，如果标签代表发育阶段（如阶段1、阶段2、阶段3），它确保潜在空间中阶段1比阶段3更接近阶段2，从而尊重生物学进程。这对于学习有意义的伪时间或轨迹表示至关重要。

*   **`cost_matrix` (成本矩阵):**
    *   **作用:** 最优传输的辅助函数。它计算从一个分布中的数据点“移动”到另一个分布中的数据点的成本。
    *   **机制:** 给定两组潜在分布（例如，来自两种不同模态）的均值 (`mu`) 和标准差 (`std`)，它计算第一组中的每个点 `i` 和第二组中的每个点 `j` 之间的成本 `C_ij`。成本定义为它们均值之间的平方欧氏距离加上它们标准差之间的平方欧氏距离。
    *   **原理:** 该成本函数量化了单个潜在表示之间的不相似性，然后由 Sinkhorn-Knopp 算法用于找到将一个分布映射到另一个分布的最佳方式。

*   **`sinkhorn_knopp_unbalanced` (非平衡 Sinkhorn-Knopp 算法):**
    *   **作用:** 使用迭代的 Sinkhorn-Knopp 算法解决非平衡最优传输 (UOT) 问题。这是对齐分布的关键算法。
    *   **机制:**
        *   接收成本矩阵 `C`、熵正则化参数 `epsilon` 以及源和目标边缘分布 `a` 和 `b`。
        *   迭代更新对偶变量 (`alpha` 和 `beta`) 直到收敛。`tau` 参数控制边缘约束的松弛，允许分布之间总质量的差异（因此是“非平衡”）。
        *   迭代的核心涉及与核矩阵 `K = exp(-C / epsilon)` 的矩阵-向量乘法。
        *   最终，它计算最优传输计划 `T*`，这是一个矩阵，指示从每个源点到每个目标点需要“移动”多少“质量”。
    *   **原理:** UOT 比平衡 OT 更灵活，因为它不要求两个分布的总质量相等。这在生物数据中通常更现实，因为不同模态之间的样本量或总表达水平可能不同。通过找到最优传输计划，它有效地学习了一个映射，将不同组学类型的数据对齐到一个共同的潜在空间中，从而实现联合分析。

*   **`calculate_minibatch_uot_loss` (小批量非平衡最优传输损失计算):**
    *   **作用:** 计算小批量内模态对之间的 UOT 损失。这是核心整合损失。
    *   **机制:**
        *   遍历 `u_dict` 中所有唯一的模态对（如 RNA 和 ATAC）。
        *   对于每对模态，提取潜在均值和标准差。
        *   为当前小批量构建均匀边缘分布 `a` 和 `b`。
        *   调用 `cost_matrix` 获取两种模态潜在点之间的成本。
        *   然后调用 `sinkhorn_knopp_unbalanced` 解决 UOT 问题并获取最优传输计划 `T*`。
        *   该模态对的 UOT 损失计算为成本矩阵 `C` 和最优传输计划 `T*` 的 Frobenius 内积（即 `sum(C * T*)`）。
        *   最后，对所有模态对的 UOT 损失进行求和或平均。
    *   **原理:** 该损失直接驱动不同模态潜在空间的对齐。通过最小化此损失，模型学习将不同组学类型的数据投影到一个共同的潜在空间中，其中对应的细胞或生物状态彼此接近，从而实现整合分析。

## 4. 核心原理总结

`CGLUE-SOE-OT` 模型是一个为单细胞多组学数据整合而设计的创新框架。其名称中的每个部分都代表了其核心原理：

*   **C (Conditional - 条件化):** 模型的编码器在学习潜在表示时，会考虑细胞类型或预定义的标签信息。这使得潜在空间能够更好地反映生物学上的分类和结构，增强了模型的可解释性和标签感知能力。
*   **GLUE (Graph-Linked Unified Embedding - 图连接统一嵌入):** 尽管此版本移除了显式的图 VAE 组件，但其核心目标仍是构建一个“统一嵌入”空间。它旨在将来自不同模态的数据映射到一个共享的低维潜在空间，从而实现跨模态的无缝整合和联合分析。
*   **SOE (Supervised Ordinal Embedding - 监督序数嵌入):** 通过引入三元组损失，模型能够利用有序的生物学标签（如发育阶段、疾病严重程度）来结构化潜在空间。它强制潜在空间中的细胞表示遵循这些有序关系，使得距离能够反映生物学上的相似性和进展。
*   **OT (Optimal Transport - 最优传输):** 这是实现多模态数据整合的关键机制。通过计算并最小化不同模态潜在分布之间的最优传输成本，模型能够有效地对齐这些分布，即使它们在原始数据空间中具有不同的特征维度和统计特性。这使得模型能够发现不同组学数据之间的对应关系，并构建一个真正整合的细胞图谱。

综上所述，`CGLUE-SOE-OT` 提供了一个全面且灵活的解决方案，用于从复杂的单细胞多组学数据中提取有意义的生物学见解，特别是在需要整合异构数据并理解有序生物学过程的场景中。

## 5. 使用示例

`examples/` 目录下提供了多个 Jupyter Notebooks，展示了如何使用 `scglue` 框架和 `CGLUE-SOE-OT` 模型进行实际的数据分析。这些示例涵盖了从数据加载、预处理、模型配置、训练到结果分析和可视化的完整流程。建议用户查阅这些 Notebooks 以获取实践指导。
